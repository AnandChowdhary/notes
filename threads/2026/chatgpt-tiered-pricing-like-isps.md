---
title: ChatGPT tiered pricing like ISPs
date: 2026-01-18T10:42:02.101Z
url: https://x.com/AnandChowdhary/status/2012837879354212459
---

ChatGPT tiers are now ISP style prices: - Free / Go: ad-subsidized, good enough for everyday queries, priced at "don't think, just use it." - GPT‑5.2 Instant: the metered, mid-tier workhorse. Fast, decent reasoning, where most volume and revenue will likely live. - GPT‑5.2 Thinking / Pro: slower, deeper, premium, reserved for high ARPU users and serious workloads. This is classic capacity partitioning. You segment compute into lanes, then attach different SLAs, price points, and business models (ads, per‑unit billing, enterprise deals) to each lane. And yes, every major model provider is probably going to copy this. Because once you treat model capacity like bandwidth, you basically end up reinventing the ISP playbook, just with more tensors and fewer fiber cuts.
