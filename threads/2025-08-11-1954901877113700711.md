---
date: 2025-08-11T13:45:11.567Z
url: https://x.com/AnandChowdhary/status/1954901877113700711
---

There are conflicting reports on how smart GPT-5 is in day-to-day usage, but I think that's not the main innovation. GPT-5 in ChatGPT is really OpenAI collapsing the model menu into a router. UX moves to an autoswitcher that spends test-time compute. When routing hits, it feels like magic. When it whiffs, it feels broken.  
  
It's important to remember that [@OpenAI](https://x.com/OpenAI) generates most of their revenue from [@ChatGPTapp](https://x.com/ChatGPTapp), not the API, which is unlike [@AnthropicAI](https://x.com/AnthropicAI) which generates most of their revenue form the API, not [@ClaudeAI](https://x.com/ClaudeAI). So it seems like that's really where this is coming from... but it's cool that the core model benefits from this behavior too.  
  
Under the hood, ChatGPT now fronts at least two families: gpt-5-main for fast paths and gpt-5-thinking for deeper work, with minis as backstops. A real time router chooses per turn using preference, correctness, and tool signals. Paid users can still force Thinking.  
  
What is new here is orchestration more than a single model leap. Day one surfaced the tradeoffs fast. A router misfire made GPT-5 feel dumber for some flows, Plus users ran into tighter Thinking allowances, and lack of model control sparked inconsistency complaints.  
  
OpenAI rolled 4o back in for Plus and promised fixes: doubled Plus limits, a clear active model indicator, a sharper decision boundary, and easier manual Thinking. Good patch notes. Now they need boring reliability.  
  
If routing lands, the model picker fades and compute budgeting becomes the UX. That can push adoption fast. API traffic roughly doubled in 24 hours and Copilot lit up on day one. As a founder, this changes dashboards, SLAs, and unit economics.  
  
It also makes evals, cost accounting, and safety trickier. You now measure a policy, not a single model. Safe completions and bio or chem high capability flags sit on the path. And watch Goodhart creep in when routers learn from preference and click signals under shift.  
  
If you are building on GPT-5, treat the router as your new runtime. Design prompts, evals, and costs around paths, not names. I am optimistic, but keep a manual gear handy.