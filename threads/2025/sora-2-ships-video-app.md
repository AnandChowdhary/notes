---
title: Sora 2 ships video app
date: 2025-10-02T15:15:19.160Z
url: https://x.com/AnandChowdhary/status/1973768691218329831
---

OpenAI is shipping Sora 2 as a TikTok-style app for video. Audio + video gen, consent-gated cameos, C2PA provenance, LLM steered feed.   
  
ChatGPT's moat expands to video. Demos wow, composition is brittle. Invites and daily caps limit risk. üïπÔ∏èüëá  
  
Form factor matters. A feed where you create, watch, and remix in one loop. LLM steered ranking turns the feed into a control surface, instead of a PageRank clone.  
  
Signals come from prompts, metadata, provenance, and engagement. Watch time, skips, reports. You can aim for safety, brand suitability, and creative diversity in the same loop. TikTok-ify!  
  
On the model side, audio and video are co-generated. Think text to scene plan to shots to camera path to sound design. You get lip sync and basic foley out of the box. It looks great for 5-10 seconds.  
  
Then reality shows up. Long range consistency drifts. Hands and physics get weird. Story beats collapse across cuts. This is where product guardrails and smart defaults matter.  
  
Consent-gated cameos are totally the right call. Faces and voices must opt in. That implies enrollment, rights management, and payouts. It also enables a talent marketplace once the pipes exist.  
  
Trade off is friction and latency. Virality likes chaos. Legal likes consent. I know which one keeps you sleeping at night.  
  
C2PA provenance is baked in. Each render is signed. Remixes attach new claims. You get a chain of custody that platforms can read and label.  
  
It will not stop fakes. It will shrink plausible deniability for actors who should know better. If you are shipping media tools, add C2PA on day one.  
  
The remix graph is the fun part and the scary part. Recursive jailbreaks happen when each remix nudges the rules a little. Five hops later you get output that no single prompt would pass.  
  
Mitigations look layered. System prompts that persist across remixes. Input and output classifiers. Signature checks before the feed takes off. Invites and daily caps to keep blast radius small while you learn.  
  
On strategy, this extends the ChatGPT moat into video. Own creation, distribution, and provenance. That yields data and defensibility even if weights spread.  
  
If I were building on this today, my wedges would be creator tools, safety infra, C2PA tooling, and evals for long range consistency. Packaging beats raw model power in this phase.  
  
Feels like early YouTube energy with a generative core. As founders, ship small, measure hard, and expect the graph to surprise you.
